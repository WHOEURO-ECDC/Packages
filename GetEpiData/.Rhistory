fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
#message(request$status_code)
message(cond)
})
}
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
adm_0 <- "EURO_COVID19_Running_v3"
data <- get_data(server, service_name=adm_0)
return(data)
}
GetEpiData()
library(httr)
#' GetEpiData function
#' This function read the running epi data online
#' @export
#'
GetEpiData <- function(){
get_data<-function(server,service_name,layer_id=0,w="1=1",rg="false",of="*"){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_Running_v3',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
id_field <- res$objectIdFieldName # if fails use this res[[1]]
n_records <- list()
n_records$max_id <- unlist(res[[2]]) %>% max()
n_records$count <- length(res[[2]])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_Running_v3',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
#message(request$status_code)
message(cond)
})
}
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
adm_0 <- "EURO_COVID19_Running_v3"
data <- get_data(server, service_name=adm_0)
return(data)
}
library(httr)
GetEpiData()
res <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_Running_v3',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
layer_id=0
w<-'1=1'
res <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_Running_v3',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
rg="false"
of="*"
res <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_Running_v3',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
id_field <- res$objectIdFieldName # if fails use this res[[1]]
id_field <- res[[1]]#res$objectIdFieldName # if fails use this res[[1]]
n_records <- list()
n_records$max_id <- unlist(res[[2]]) %>% max()
n_records$count <- length(res[[2]])
res <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_Running_v3',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
res
n_records <- list()
n_records
unlist(res[[2]])
res <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_ADM0_Cases',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
id_field <- res$objectIdFieldName
n_records <- list()
n_records$max_id <- unlist(res[[2]]) %>% max()
n_records$count <- length(res[[2]])
library(dplyr)
n_records <- list()
n_records$max_id <- unlist(res[[2]]) %>% max()
n_records$count <- length(res[[2]])
res <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_Running_v3',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
id_field <- res[[1]]#res$objectIdFieldName # if fails use this res[[1]]
n_records <- list()
n_records$max_id <- unlist(res[[2]]) %>% max()
n_records$count <- length(res[[2]])
id_field <- res[[1]]
id_field
res <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_ADM0_Cases',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
res <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_Running_v3',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
get_data <- function(server,service_name,layer_id=0,w="1=1",rg="false",of="*"){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8")) %>%
fromJSON(., flatten = TRUE)
n_records <- res %>% .[2] %>%  as.data.frame(.) %>%#get second list and convert into a data frame
summarise(max_id=max(.[1]), count=n())
id_field <- unlist(res[1])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,service_type,layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
message(request$status_code)
message(cond)
})
}
################################
# 1. Get Data
# retrieves data from ArcGIS services and saves it as CSV file.
###############################
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
service_cum <- "EURO_COVID19_ADM0_Cases"
service_daily <- "EURO_COVID19_Running_v3"
service_type <- "FeatureServer"
# download cumulative data and save as csv
# (this step is done to avoid unnecessarily hammering against the hosting server :))
get_data(server, service_cum) %>% mutate(POPULATION = CENTER_LAT) %>%
select(WHO_CODE,ADM0_VIZ_N,CasesTotal,CasesN3,DeathsTotal,DeathsN3,POPULATION) %>%
mutate(ADM0_VIZ_N = gsub("\\[.*","",ADM0_VIZ_N)) %>%
write_csv("cumulative_cases.csv")
# download incident data
get_data(server, service_daily) %>%
select(WHO_CODE,ADM0NAME,DateReport,NewCases,NewDeaths,TotalCases,TotalDeaths) %>%
write_csv("daily_incidence.csv")
get_data(server, service_cum) %>% mutate(POPULATION = CENTER_LAT) %>%
select(WHO_CODE,ADM0_VIZ_N,CasesTotal,CasesN3,DeathsTotal,DeathsN3,POPULATION) %>%
mutate(ADM0_VIZ_N = gsub("\\[.*","",ADM0_VIZ_N))
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
service_cum <- "EURO_COVID19_ADM0_Cases"
service_daily <- "EURO_COVID19_Running_v3"
service_type <- "FeatureServer"
pkgs <- c( "tidyverse", "httr", "jsonlite","readxl","yesno")
for (i in pkgs) {
if (!i %in% installed.packages()) {
install.packages(i)
}
library(i, character.only = TRUE)
}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# sets the working directory to the current file location
get_data <- function(server,service_name,layer_id=0,w="1=1",rg="false",of="*"){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8")) %>%
fromJSON(., flatten = TRUE)
n_records <- res %>% .[2] %>%  as.data.frame(.) %>%#get second list and convert into a data frame
summarise(max_id=max(.[1]), count=n())
id_field <- unlist(res[1])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,service_type,layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
message(request$status_code)
message(cond)
})
}
get_data(server, service_cum) %>% mutate(POPULATION = CENTER_LAT) %>%
select(WHO_CODE,ADM0_VIZ_N,CasesTotal,CasesN3,DeathsTotal,DeathsN3,POPULATION) %>%
mutate(ADM0_VIZ_N = gsub("\\[.*","",ADM0_VIZ_N)) %>%
write_csv("cumulative_cases.csv")
get_data(server, service_cum) %>% mutate(POPULATION = CENTER_LAT) %>%
select(WHO_CODE,ADM0_VIZ_N,CasesTotal,CasesN3,DeathsTotal,DeathsN3,POPULATION) %>%
mutate(ADM0_VIZ_N = gsub("\\[.*","",ADM0_VIZ_N))
get_data(server, service_daily) %>%
select(WHO_CODE,ADM0NAME,DateReport,NewCases,NewDeaths,TotalCases,TotalDeaths)
get_data<-function(server,service_name,layer_id=0,w="1=1",rg="false",of="*"){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8")) %>%
fromJSON(., flatten = TRUE)
n_records <- res %>% .[2] %>%  as.data.frame(.) %>%#get second list and convert into a data frame
summarise(max_id=max(.[1]), count=n())
id_field <- unlist(res[1])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,service_type,layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
message(request$status_code)
message(cond)
})
}
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
adm_0 <- "EURO_COVID19_Running_v3"
data <- get_data(server, service_name=adm_0)
#' GetEpiData function
#' This function read the running epi data online
#' @export
#'
GetEpiData <- function(){
get_data<-function(server,service_name,layer_id=0,w="1=1",rg="false",of="*"){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8")) %>%
fromJSON(., flatten = TRUE)
n_records <- res %>% .[2] %>%  as.data.frame(.) %>%#get second list and convert into a data frame
summarise(max_id=max(.[1]), count=n())
id_field <- unlist(res[1])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,service_type,layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
message(request$status_code)
message(cond)
})
}
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
adm_0 <- "EURO_COVID19_Running_v3"
data <- get_data(server, service_name=adm_0)
return(data)
}
GetEpiData()
getwd()
setwd('C:/Users/romanc/Documents/GitHub/Packages/GetEpiData')
document()
library(devtools)
document()
rm(list = c("GetEpiData"))
document()
install_github('WHOEURO-ECDC/Packages/GetEpiData')
