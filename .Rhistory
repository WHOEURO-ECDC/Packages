# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
id_field <- res$objectIdFieldName # if fails use this res[[1]]
n_records <- list()
n_records$max_id <- unlist(res[[2]]) %>% max()
n_records$count <- length(res[[2]])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
#message(request$status_code)
message(cond)
})
}
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
adm_0 <- "EURO_COVID19_ADM0_Cases"
country_pop <- get_data(server, adm_0) %>%
select(ADM0_NAME,WHO_CODE,Population=CENTER_LAT) %>%
mutate(ADM0_NAME=str_to_title(ADM0_NAME))
country_pop <- WHOCountryNames(country_pop,ADM0_NAME)
return(country_pop)
}
population<-GetPopulation() %>%
select(ADM0NAME=ADM0_NAME,UNPOP2019=Population)
get_data<-function(server,service_name,layer_id=0,w="1=1",rg="false",of="*"){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
id_field <- res$objectIdFieldName # if fails use this res[[1]]
n_records <- list()
n_records$max_id <- unlist(res[[2]]) %>% max()
n_records$count <- length(res[[2]])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
#message(request$status_code)
message(cond)
})
}
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
adm_0 <- "EURO_COVID19_ADM0_Cases"
country_pop <- get_data(server, adm_0) %>%
select(ADM0_NAME,WHO_CODE,Population=CENTER_LAT) %>%
mutate(ADM0_NAME=str_to_title(ADM0_NAME))
get_data<-function(server,service_name,layer_id=0,w="1=1",rg="false",of="*"){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
id_field <- res$objectIdFieldName # if fails use this res[[1]]
n_records <- list()
n_records$max_id <- unlist(res[[2]]) %>% max()
n_records$count <- length(res[[2]])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
#message(request$status_code)
message(cond)
})
}
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
adm_0 <- "EURO_COVID19_ADM0_Cases"
country_pop <- get_data(server, adm_0) %>%
select(ADM0_NAME,WHO_CODE,Population=CENTER_LAT) %>%
mutate(ADM0_NAME=str_to_title(ADM0_NAME))
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_ADM0_Cases',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
id_field <- res$objectIdFieldName # if fails use this res[[1]]
n_records <- list()
n_records$max_id <- unlist(res[[2]]) %>% max()
n_records$count <- length(res[[2]])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_ADM0_Cases',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
#message(request$status_code)
message(cond)
})
}
res <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_ADM0_Cases',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
id_field <- res$objectIdFieldName # if fails use this res[[1]]
res
id_field <- res[[1]]#res$objectIdFieldName # if fails use this res[[1]]
#' GetPopulation function
#' This function reads the population data from the EURO dashboard
#' @export
GetPopulation<-function(){
get_data<-function(server,service_name,layer_id=0,w="1=1",rg="false",of="*"){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_ADM0_Cases',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
id_field <- res[[1]]#res$objectIdFieldName # if fails use this res[[1]]
n_records <- list()
n_records$max_id <- unlist(res[[2]]) %>% max()
n_records$count <- length(res[[2]])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_ADM0_Cases',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
#message(request$status_code)
message(cond)
})
}
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
adm_0 <- "EURO_COVID19_ADM0_Cases"
country_pop <- get_data(server, adm_0) %>%
select(ADM0_NAME,WHO_CODE,Population=CENTER_LAT) %>%
mutate(ADM0_NAME=str_to_title(ADM0_NAME))
country_pop <- WHOCountryNames(country_pop,ADM0_NAME)
return(country_pop)
}
GetPopulation()
res <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_ADM0_Cases',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
id_field <- res[[1]]#res$objectIdFieldName # if fails use this res[[1]]
n_records <- list()
n_records$max_id <- unlist(res[[2]]) %>% max()
n_records$count <- length(res[[2]])
res[[2]]
res
res <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_ADM0_Cases',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
res
res <- content(GET(url = paste('https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services',
'EURO_COVID19_ADM0_Cases',"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
id_field <- res$objectIdFieldName # if fails use this res[[1]]
population<-GetPopulation() %>%
select(ADM0NAME=ADM0_NAME,UNPOP2019=Population)
install_github('EUROHIM/Packages/GetEpiData')
library(devtools)
install_github('EUROHIM/Packages/GetEpiData')
install_github('WHOEURO-ECDC/Packages/GetEpiData')
GetEpiData()
library(GetEpiData)
GetEpiData()
GetEpiData()
install_github('WHOEURO-ECDC/Packages/GetPopulation')
library(GetPopulation)
GetPopulation()
install_github('WHOEURO-ECDC/Packages/GetEpiData')
library(devtools)
install_github('WHOEURO-ECDC/Packages/GetEpiData')
GetEpiData()
library(GetEpiData)
GetEpiData()
rm(list())
library(devtools)
install_github('WHOEURO-ECDC/Packages/GetEpiData')
library(GetEpiData)
GetEpiData()
shiny::runApp('GitHub/Shiny_PHSM/app_multiple')
runApp('GitHub/HIM/SummaryTable')
runApp('GitHub/Shiny_PHSM/app_single')
library(GetPopulation)
GetPopulation()
GetEpiData <- function(){
get_data<-function(server,service_name,layer_id=0,w="1=1",rg="false",of="*"){
#gets data from an Esri feature service.
#
# args:
#   server (string): name of the arcgis server
#   service_name (string): name of the feature service
#   layer id (int): id of the layer, default = 0
#   w (string): where condition, default = "1=1",
#   rg(string): defines whether geometry is exported. Must be either 'false' or 'true'. Note values must be a string not a boolean
#   of (string): list of output fields. Must be a string not a list or vector. Default is set to export all columns ("*)
#   f (string): output format
#
# returns:
# data (tibble): feature service converted to a tibble
out <- tryCatch(
{
# Get the maximum id. This is need to define the number of calls required to fetch data
res <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = w,
returnGeometry = rg,
returnIdsOnly = TRUE,
f = "json"),
as = "text", encoding = "UTF-8"))
id_field <- res$objectIdFieldName # if fails use this res[[1]]
n_records <- list()
n_records$max_id <- unlist(res[[2]]) %>% max()
n_records$count <- length(res[[2]])
# Do until all records are exported
# Retrieve recrords from the feature service and merge into a single data frame
id <- 0
data <- tibble()
while (id<n_records$max_id) {
records <- content(GET(url = paste(server,service_name,"FeatureServer",layer_id,"query?",sep="/"),
query = list(
where = paste(w,"and",id_field,">=",id) ,
returnGeometry = rg,
outFields = of,
returnIdsOnly = FALSE,
f = "json")),
as = "text", encoding = "UTF-8") %>%
fromJSON(., flatten = TRUE)  %>% .$features %>% as_tibble() %>%
rename_all(list(~ sub(".*?[[:punct:]]", "",.)))
id_new <- records %>% summarise(max(!!as.name(id_field))) %>% pull
if(nrow(records)==0 | id_new == id ) {
#if no records are returned, break loop
break
} else{
data <- rbind(data,records)
id <- id_new +1
}
}
#convert esri data to dttm
data <- data %>%  mutate_if(~ (is.double(.) && min(., na.rm = TRUE) > 1e12 && min(., na.rm = TRUE) %% 1000 ==0) , list(~as.POSIXct(./1000,origin="1970-01-01",tz="GMT")))
# retrun data
return(data)
},
error = function(cond) {
message(paste0("Request failed. Please review the paramaters."))
#message(request$status_code)
message(cond)
})
}
server <- "https://services.arcgis.com/5T5nSi527N4F7luB/ArcGIS/rest/services"
service_daily <- "EURO_COVID19_Running_v3"
service_type <- "FeatureServer"
data<-get_data(server, service_daily) #%>%
#select(WHO_CODE,ADM0NAME,DateReport,NewCases,NewDeaths,TotalCases,TotalDeaths)
return(data)
}
GetEpiData()
getwd()
setwd('C:/Users/romanc/Documents/GitHub/Packages')
install('GetEpiData')
library(devtools)
install('GetEpiData')
#Packages needed to use all of these packages
#Some custom packages make use of other custom packages, important to have them all downloaded
Packages_CRAN<-c('stats','ggplot2','hablar','devtools','readxl','Rcpp','zoo','dplyr','tidyr','httr','jsonlite','lubridate','cowplot','stringr','stats','imputeTS')
Packages_Custom<-c('WHOCountryNames',
'RtChart',
'GetEpiData',
'BuildExtendedEpiDataset',
'SpaguettiPlot',
'ReadSeverityExcel','PHSMChart','TableIndicators')
for (i in Packages_CRAN) {
print(i)
if (!i %in% installed.packages())
{install.packages(i)}
library(i, character.only = TRUE)
}
for (i in Packages_Custom) {
print(i)
if (!i %in% installed.packages())
{install_github(paste0('WHOEURO-ECDC/Packages/',i))}
library(i, character.only = TRUE)
}
Packages_Custom<-c('WHOCountryNames',
'RtChart',
'GetEpiData',
'BuildExtendedEpiDataset',
'SpaguettiPlot',
'ReadSeverityExcel','PHSMChart','TableIndicators','GetPopulation')
for (i in Packages_Custom) {
print(i)
if (!i %in% installed.packages())
{install_github(paste0('WHOEURO-ECDC/Packages/',i))}
library(i, character.only = TRUE)
}
shiny::runApp('~/GitHub/CalibrationTool')
MainDataset<-GetEpiData() %>%
WHOCountryNames(ADM0NAME) %>%
mutate(DateReport=as.Date(DateReport))
runApp('~/GitHub/CalibrationTool')
